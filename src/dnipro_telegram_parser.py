#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Parser for Dnipro Oblenergo (Telegram)

import asyncio
import re
import json
from datetime import datetime, date, timedelta
from zoneinfo import ZoneInfo
from playwright.async_api import async_playwright
import os

TZ = ZoneInfo("Europe/Kyiv")
URL = "https://t.me/s/cek_info"
OUTPUT_FILE = "output/Dneproblenergo.json"

LOG_DIR = "logs"
FULL_LOG_FILE = os.path.join(LOG_DIR, "full_log.log")

os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs("output", exist_ok=True)

# –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ—à—É–∫—É –ø–æ—Å—Ç—ñ–≤ –∑ –≥—Ä–∞—Ñ—ñ–∫–∞–º–∏
KEYWORDS = [
    "–≥—Ä–∞—Ñ—ñ–∫–∏ –ø–æ–≥–æ–¥–∏–Ω–Ω–∏—Ö –≤—ñ–¥–∫–ª—é—á–µ–Ω—å",
    "–ì–ü–í", 
    "–≥–æ–¥–∏–Ω–∏ –≤—ñ–¥—Å—É—Ç–Ω–æ—Å—Ç—ñ –µ–ª–µ–∫—Ç—Ä–æ–ø–æ—Å—Ç–∞—á–∞–Ω–Ω—è",
    "–±—É–¥—É—Ç—å –¥—ñ—è—Ç–∏ –≥—Ä–∞—Ñ—ñ–∫–∏",
    "–ø–ª–∞–Ω–æ–≤—ñ —Ä–æ–±–æ—Ç–∏",
    "–≤—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –µ–ª–µ–∫—Ç—Ä–æ–ø–æ—Å—Ç–∞—á–∞–Ω–Ω—è",
    "–≥—Ä–∞—Ñ—ñ–∫ –≤—ñ–¥–∫–ª—é—á–µ–Ω—å",
    "–∑–∞—Å—Ç–æ—Å–æ–≤—É–≤–∞—Ç–∏–º—É—Ç—å—Å—è –≤—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –Ω–∞—Å—Ç—É–ø–Ω–∏—Ö —á–µ—Ä–≥",
    "–≤—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –Ω–∞—Å—Ç—É–ø–Ω–∏—Ö —á–µ—Ä–≥",
    "—á–µ—Ä–≥–∞:"
]


def log(message: str):
    timestamp = datetime.now(TZ).strftime("%Y-%m-%d %H:%M:%S")
    line = f"{timestamp} [dnipro_parser] {message}"
    print(line)
    with open(FULL_LOG_FILE, "a", encoding="utf-8") as f:
        f.write(line + "\n")


def time_to_hour(hhmm: str) -> float:
    hh, mm = map(int, hhmm.split(":"))
    return hh + (mm / 60.0)


def is_schedule_post(text: str) -> bool:
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ –º—ñ—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –ø—Ä–æ –≥—Ä–∞—Ñ—ñ–∫–∏"""
    if not text:
        return False
    text_lower = text.lower()
    return any(keyword.lower() in text_lower for keyword in KEYWORDS)


async def fetch_posts() -> list:
    """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –ø–æ—Å—Ç–∏ –∑ Telegram —Ç–∞ —Ñ—ñ–ª—å—Ç—Ä—É—î —ó—Ö –∑–∞ –∫–ª—é—á–æ–≤–∏–º–∏ —Å–ª–æ–≤–∞–º–∏"""
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True, 
            args=[
                "--no-sandbox",
                "--disable-setuid-sandbox",
                "--disable-dev-shm-usage",
                "--disable-blink-features=AutomationControlled"
            ]
        )
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = await context.new_page()
        
        try:
            log(f"üåê –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é {URL}...")
            await page.goto(URL, wait_until="domcontentloaded", timeout=60000)
            await page.wait_for_selector(".tgme_widget_message", timeout=30000)
            
            # –ß–µ–∫–∞—î–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤–æ –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥—É –∫–æ–Ω—Ç–µ–Ω—Ç—É
            await page.wait_for_timeout(3000)
            
            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –ø–æ—Å—Ç–∏
            posts = await page.query_selector_all(".tgme_widget_message")
            log(f"‚úîÔ∏è –ó–Ω–∞–π–¥–µ–Ω–æ {len(posts)} –ø–æ—Å—Ç—ñ–≤ –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ")
            
            filtered_posts = []
            
            for post in posts:
                try:
                    # –û—Ç—Ä–∏–º—É—î–º–æ —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
                    text_element = await post.query_selector(".tgme_widget_message_text")
                    if not text_element:
                        continue
                    
                    post_text = await text_element.inner_text()
                    
                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ü–µ –ø–æ—Å—Ç –∑ –≥—Ä–∞—Ñ—ñ–∫–æ–º
                    if not is_schedule_post(post_text):
                        continue
                    
                    # –û—Ç—Ä–∏–º—É—î–º–æ –¥–∞—Ç—É –ø–æ—Å—Ç–∞
                    date_element = await post.query_selector(".tgme_widget_message_date time")
                    post_date_str = None
                    if date_element:
                        post_date_str = await date_element.get_attribute("datetime")
                    
                    filtered_posts.append({
                        'text': post_text,
                        'date': post_date_str
                    })
                    
                except Exception as e:
                    log(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –ø–æ—Å—Ç–∞: {e}")
                    continue
            
            log(f"‚úîÔ∏è –ó–Ω–∞–π–¥–µ–Ω–æ {len(filtered_posts)} –ø–æ—Å—Ç—ñ–≤ –∑ –≥—Ä–∞—Ñ—ñ–∫–∞–º–∏")
            
        finally:
            await browser.close()
            
        return filtered_posts


def put_interval(result: dict, group_id: str, t1: float, t2: float) -> None:
    """–û—Ç–º–µ—á–∞–µ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ"""
    # –£–±–∏—Ä–∞–µ–º —Å–¥–≤–∏–≥ –Ω–∞ +1 —á–∞—Å, —Ç–∞–∫ –∫–∞–∫ –≤ –¶–ï–ö –≤—Ä–µ–º—è —É–∫–∞–∑–∞–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
    # t1 += 1.0
    # t2 += 1.0
    
    for hour in range(1, 25):
        h_start = float(hour - 1)  # —á–∞—Å 1 = 0:00-1:00
        h_mid = h_start + 0.5
        h_end = h_start + 1.0

        first_off = (t1 < h_mid and t2 > h_start)
        second_off = (t1 < h_end and t2 > h_mid)

        if not first_off and not second_off:
            continue

        key = str(hour)

        if first_off and second_off:
            result[group_id][key] = "no"
        elif first_off:
            result[group_id][key] = "first"
        elif second_off:
            result[group_id][key] = "second"


def extract_date_from_post(text: str, debug: bool = False) -> str:
    """–í–∏—Ç—è–≥—É—î –¥–∞—Ç—É –∑ —Ç–µ–∫—Å—Ç—É –ø–æ—Å—Ç–∞ –¥–ª—è —Ñ–æ—Ä–º–∞—Ç—É –¶–ï–ö"""
    months = {
        '—Å—ñ—á–Ω—è': '01', '–ª—é—Ç–æ–≥–æ': '02', '–±–µ—Ä–µ–∑–Ω—è': '03', '–∫–≤—ñ—Ç–Ω—è': '04',
        '—Ç—Ä–∞–≤–Ω—è': '05', '—á–µ—Ä–≤–Ω—è': '06', '–ª–∏–ø–Ω—è': '07', '—Å–µ—Ä–ø–Ω—è': '08',
        '–≤–µ—Ä–µ—Å–Ω—è': '09', '–∂–æ–≤—Ç–Ω—è': '10', '–ª–∏—Å—Ç–æ–ø–∞–¥–∞': '11', '–≥—Ä—É–¥–Ω—è': '12'
    }
    
    # –°–ø—Ä–æ–±–∞ 1: –®—É–∫–∞—î–º–æ –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç—ñ "19 –ì–†–£–î–ù–Ø" (—è–∫ —É –ø—Ä–∏–∫–ª–∞–¥—ñ –¶–ï–ö)
    date_pattern_caps = r'(\d{1,2})\s+(' + '|'.join([m.upper() for m in months.keys()]) + r')'
    
    matches = list(re.finditer(date_pattern_caps, text, re.IGNORECASE))
    
    if debug and matches:
        log(f"   üîç –ó–Ω–∞–π–¥–µ–Ω–æ {len(matches)} –∑–±—ñ–≥—ñ–≤ –∑ –≤–µ–ª–∏–∫–∏–º–∏ –ª—ñ—Ç–µ—Ä–∞–º–∏")
    
    for idx, match in enumerate(matches, 1):
        day_num = match.group(1)
        month_name = match.group(2).lower()
        
        if debug:
            log(f"   üìç –ó–±—ñ–≥ {idx}: '{day_num} {month_name}'")
        
        day = day_num.zfill(2)
        month = months.get(month_name)
        
        if month:
            date_str = f"{day}.{month}.{datetime.now(TZ).year}"
            if debug:
                log(f"   ‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –¥–∞—Ç—É: {date_str}")
            return date_str
    
    # –°–ø—Ä–æ–±–∞ 2: –®—É–∫–∞—î–º–æ "—É [–¥–µ–Ω—å_—Ç–∏–∂–Ω—è], [—á–∏—Å–ª–æ] [–º—ñ—Å—è—Ü—å]"
    date_pattern_with_day = r'—É\s+([\w º\']+),\s+(\d{1,2})\s+(' + '|'.join(months.keys()) + r')'
    
    matches = list(re.finditer(date_pattern_with_day, text, re.IGNORECASE))
    
    if debug and matches:
        log(f"   üîç –ó–Ω–∞–π–¥–µ–Ω–æ {len(matches)} –∑–±—ñ–≥—ñ–≤ –∑ –¥–Ω–µ–º —Ç–∏–∂–Ω—è")
    
    for idx, match in enumerate(matches, 1):
        day_of_week = match.group(1).lower()
        day_num = match.group(2)
        month_name = match.group(3).lower()
        
        if debug:
            log(f"   üìç –ó–±—ñ–≥ {idx}: '—É {day_of_week}, {day_num} {month_name}'")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —â–æ —Ü–µ –¥—ñ–π—Å–Ω–æ –¥–µ–Ω—å —Ç–∏–∂–Ω—è
        days_of_week = [
            '–ø–æ–Ω–µ–¥—ñ–ª–æ–∫', '–≤—ñ–≤—Ç–æ—Ä–æ–∫', '—Å–µ—Ä–µ–¥—É', '—á–µ—Ç–≤–µ—Ä', '–ø\'—è—Ç–Ω–∏—Ü—é', '–ø º—è—Ç–Ω–∏—Ü—é', '—Å—É–±–æ—Ç—É', '–Ω–µ–¥—ñ–ª—é',
            '–ø–æ–Ω–µ–¥—ñ–ª–∫–∞', '–≤—ñ–≤—Ç–æ—Ä–∫–∞', '—Å–µ—Ä–µ–¥–∏', '—á–µ—Ç–≤–µ—Ä–≥–∞', '–ø\'—è—Ç–Ω–∏—Ü—ñ', '–ø º—è—Ç–Ω–∏—Ü—ñ', '—Å—É–±–æ—Ç–∏', '–Ω–µ–¥—ñ–ª—ñ'
        ]
        
        if day_of_week in days_of_week:
            if debug:
                log(f"   ‚úÖ '{day_of_week}' - —Ü–µ –¥–µ–Ω—å —Ç–∏–∂–Ω—è!")
            
            day = day_num.zfill(2)
            month = months.get(month_name)
            
            if month:
                date_str = f"{day}.{month}.{datetime.now(TZ).year}"
                return date_str
    
    # –°–ø—Ä–æ–±–∞ 3: –®—É–∫–∞—î–º–æ –ø—Ä–æ—Å—Ç–æ "[—á–∏—Å–ª–æ] [–º—ñ—Å—è—Ü—å]" –±–µ–∑ –¥–Ω—è —Ç–∏–∂–Ω—è
    date_pattern_simple = r'(\d{1,2})\s+(' + '|'.join(months.keys()) + r')'
    
    matches_simple = list(re.finditer(date_pattern_simple, text, re.IGNORECASE))
    
    if debug and matches_simple:
        log(f"   üîç –ó–Ω–∞–π–¥–µ–Ω–æ {len(matches_simple)} –∑–±—ñ–≥—ñ–≤ –±–µ–∑ –¥–Ω—è —Ç–∏–∂–Ω—è")
    
    for idx, match in enumerate(matches_simple, 1):
        day_num = match.group(1)
        month_name = match.group(2).lower()
        
        if debug:
            log(f"   üìç –ó–±—ñ–≥ {idx}: '{day_num} {month_name}'")
        
        day = day_num.zfill(2)
        month = months.get(month_name)
        
        if month:
            date_str = f"{day}.{month}.{datetime.now(TZ).year}"
            if debug:
                log(f"   ‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –¥–∞—Ç—É: {date_str}")
            return date_str
    
    return None


def parse_schedule_from_text(text: str) -> dict:
    """–ü–∞—Ä—Å–∏—Ç—å –≥—Ä–∞—Ñ—ñ–∫ –≤—ñ–¥–∫–ª—é—á–µ–Ω—å –∑ —Ç–µ–∫—Å—Ç—É –¥–ª—è —Ñ–æ—Ä–º–∞—Ç—É –¶–ï–ö –î–Ω—ñ–ø—Ä–æ"""
    result = {}
    
    # –ò—â–µ–º –≤—Å–µ –≥—Ä—É–ø–ø—ã –∏ –∏—Ö –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ç–µ–∫—Å—Ç–µ
    group_pattern = r'üìå\s*(\d+\.\d+)\s*—á–µ—Ä–≥[–∞–∏]:'
    group_matches = list(re.finditer(group_pattern, text))
    
    if not group_matches:
        return result
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –≥—Ä—É–ø–ø—É
    for i, group_match in enumerate(group_matches):
        group_num = group_match.group(1)
        group_id = f"GPV{group_num}"
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≥—Ä—É–ø–ø—É - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤–µ–∑–¥–µ –µ—Å—Ç—å —Å–≤–µ—Ç
        result[group_id] = {str(h): "yes" for h in range(1, 25)}
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã
        start_pos = group_match.end()
        if i + 1 < len(group_matches):
            # –ï—Å—Ç—å —Å–ª–µ–¥—É—é—â–∞—è –≥—Ä—É–ø–ø–∞ - –±–µ—Ä–µ–º —Ç–µ–∫—Å—Ç –¥–æ –Ω–µ—ë
            end_pos = group_matches[i + 1].start()
        else:
            # –ü–æ—Å–ª–µ–¥–Ω—è—è –≥—Ä—É–ø–ø–∞ - –±–µ—Ä–µ–º –¥–æ –∫–æ–Ω—Ü–∞ –∏–ª–∏ –¥–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
            warning_match = re.search(r'–ü–æ–ø–µ—Ä–µ–¥–∂–∞—î–º–æ', text[start_pos:])
            if warning_match:
                end_pos = start_pos + warning_match.start()
            else:
                end_pos = len(text)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —ç—Ç–æ–π –≥—Ä—É–ø–ø—ã
        group_text = text[start_pos:end_pos]
        
        # –ò—â–µ–º –≤—Å–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –≤ —Ç–µ–∫—Å—Ç–µ –≥—Ä—É–ø–ø—ã
        intervals = re.findall(r'–∑\s+(\d{1,2}:\d{2})\s+–¥–æ\s+(\d{1,2}:\d{2})', group_text)
        
        for start_time, end_time in intervals:
            try:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤ —á–∞—Å—ã (float)
                t1 = time_to_hour(start_time)
                t2 = time_to_hour(end_time)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–π –∫–æ–≥–¥–∞ –≤—Ä–µ–º—è –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ –ø–æ–ª–Ω–æ—á—å
                if t2 <= t1:  # –Ω–∞–ø—Ä–∏–º–µ—Ä, –∑ 23:30 –¥–æ 02:30
                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –¥–≤–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞: –¥–æ –ø–æ–ª—É–Ω–æ—á–∏ –∏ –ø–æ—Å–ª–µ –ø–æ–ª—É–Ω–æ—á–∏
                    put_interval(result, group_id, t1, 24.0)  # –¥–æ –ø–æ–ª—É–Ω–æ—á–∏
                    put_interval(result, group_id, 0.0, t2)   # –ø–æ—Å–ª–µ –ø–æ–ª—É–Ω–æ—á–∏
                else:
                    put_interval(result, group_id, t1, t2)
                    
            except Exception as e:
                log(f"‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É —ñ–Ω—Ç–µ—Ä–≤–∞–ª—É {start_time}-{end_time}: {e}")
                continue
    
    return result


async def main():
    log("‚è≥ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é Telegram-–∫–∞–Ω–∞–ª...")
    posts = await fetch_posts()
    
    if not posts:
        log("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø–æ—Å—Ç—ñ–≤ –∑ –≥—Ä–∞—Ñ—ñ–∫–∞–º–∏")
        return False

    today = datetime.now(TZ).date()
    tomorrow = today + timedelta(days=1)
    today_str = today.strftime("%d.%m.%Y")
    tomorrow_str = tomorrow.strftime("%d.%m.%Y")

    results_for_all_dates = {}
    processed_dates = set()

    log(f"üîç –û–±—Ä–æ–±–∫–∞ {len(posts)} –ø–æ—Å—Ç—ñ–≤...")
    
    for idx, post in enumerate(posts, 1):
        try:
            # –í–∏—Ç—è–≥—É—î–º–æ –¥–∞—Ç—É –∑ —Ç–µ–∫—Å—Ç—É (–∑ debug –¥–ª—è –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –ø–æ—Å—Ç—ñ–≤)
            debug = (idx >= 10)
            date_str = extract_date_from_post(post['text'], debug=debug)
            
            if not date_str:
                # Debug: –ø–æ–∫–∞–∑—É—î–º–æ –ø–µ—Ä—à—ñ 300 —Å–∏–º–≤–æ–ª—ñ–≤ —Ç–µ–∫—Å—Ç—É –ø–æ—Å—Ç–∞
                if idx >= 10:  # –¢—ñ–ª—å–∫–∏ –¥–ª—è –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –ø–æ—Å—Ç—ñ–≤
                    log(f"üìÑ –ü–æ—Å—Ç {idx}: –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–∞—Ç–∏ –≤ —Ç–µ–∫—Å—Ç—ñ")
                    log(f"   –ü–æ—á–∞—Ç–æ–∫ —Ç–µ–∫—Å—Ç—É: {post['text'][:300]}")
                else:
                    log(f"üìÑ –ü–æ—Å—Ç {idx}: –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–∞—Ç–∏ –≤ —Ç–µ–∫—Å—Ç—ñ")
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —è–∫—â–æ –Ω–µ today/tomorrow
            if date_str not in (today_str, tomorrow_str):
                log(f"‚è≠Ô∏è –ü–æ—Å—Ç {idx}: {date_str} (–Ω–µ —Å—å–æ–≥–æ–¥–Ω—ñ/–∑–∞–≤—Ç—Ä–∞)")
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ —è–∫—â–æ –≤–∂–µ –æ–±—Ä–æ–±–ª–µ–Ω–æ
            if date_str in processed_dates:
                log(f"‚ÑπÔ∏è –ü–æ—Å—Ç {idx}: {date_str} ‚Äî –≤–∂–µ –æ–±—Ä–æ–±–ª–µ–Ω–æ")
                continue
            
            log(f"üìÖ –ü–æ—Å—Ç {idx}: –æ–±—Ä–æ–±–ª—è—é –≥—Ä–∞—Ñ—ñ–∫ –¥–ª—è {date_str}")
            
            # –ü–∞—Ä—Å–∏–º–æ –≥—Ä–∞—Ñ—ñ–∫
            result = parse_schedule_from_text(post['text'])
            
            if not result:
                log(f"‚ö†Ô∏è –ü–æ—Å—Ç {idx}: –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ —É —Ç–µ–∫—Å—Ç—ñ")
                continue
            
            # –ß–∞—Å –æ–Ω–æ–≤–ª–µ–Ω–Ω—è - –±–µ—Ä–µ–º–æ –ø–æ—Ç–æ—á–Ω–∏–π —á–∞—Å
            current_time = datetime.now(TZ).strftime("%H:%M")
            log(f"üïí –ß–∞—Å –æ–Ω–æ–≤–ª–µ–Ω–Ω—è: {current_time}")
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ timestamp
            day_int, month_int, year_int = map(int, date_str.split("."))
            date_dt = datetime(year_int, month_int, day_int, tzinfo=TZ)
            date_ts = int(date_dt.timestamp())
            
            results_for_all_dates[str(date_ts)] = result
            processed_dates.add(date_str)
            log(f"‚úÖ –î–æ–¥–∞–Ω–æ –≥—Ä–∞—Ñ—ñ–∫ –¥–ª—è {date_str}: {len(result)} –≥—Ä—É–ø")
            
        except Exception as e:
            log(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ –ø–æ—Å—Ç–∞ {idx}: {e}")
            continue

    if not results_for_all_dates:
        log("‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∂–æ–¥–Ω–∏—Ö –≥—Ä–∞—Ñ—ñ–∫—ñ–≤ –≤—ñ–¥–∫–ª—é—á–µ–Ω—å!")
        return False

    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ DIFF
    if os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, "r", encoding="utf-8") as f:
            old_json = json.load(f)
        old_data = old_json.get("fact", {}).get("data", {})

        if json.dumps(old_data, sort_keys=True) == json.dumps(results_for_all_dates, sort_keys=True):
            log("‚ÑπÔ∏è –î–∞–Ω—ñ –Ω–µ –∑–º—ñ–Ω–∏–ª–∏—Å—è ‚Äî JSON –Ω–µ –æ–Ω–æ–≤–ª—é—î–º–æ")
            return False

    # –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ –ø–æ—Ç–æ—á–Ω—É –¥–∞—Ç—É —ñ —á–∞—Å –æ–Ω–æ–≤–ª–µ–Ω–Ω—è
    update_formatted = datetime.now(TZ).strftime("%d.%m.%Y %H:%M")
    log(f"üïë –§—ñ–Ω–∞–ª—å–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è: {update_formatted}")

    # –°–æ—Ä—Ç—É—î–º–æ –¥–∞—Ç–∏ –≤—ñ–¥ –º–µ–Ω—à–æ—ó –¥–æ –±—ñ–ª—å—à–æ—ó
    sorted_results = dict(sorted(results_for_all_dates.items(), key=lambda x: int(x[0])))
    results_for_all_dates = sorted_results

    # –§–æ—Ä–º—É—î–º–æ JSON
    new_json = {
        "regionId": "Dnipro",
        "lastUpdated": datetime.now(ZoneInfo("UTC")).strftime("%Y-%m-%dT%H:%M:%S.%f")[:-3] + "Z",
        "fact": {
            "data": results_for_all_dates,
            "update": update_formatted,
            "today": int(datetime(today.year, today.month, today.day, tzinfo=TZ).timestamp())
        },
        "preset": {
            "time_zone": {
                str(i): [f"{i - 1:02d}-{i:02d}", f"{i - 1:02d}:00", f"{i:02d}:00"]
                for i in range(1, 25)
            },
            "time_type": {
                "yes": "–°–≤—ñ—Ç–ª–æ —î",
                "maybe": "–ú–æ–∂–ª–∏–≤–µ –≤—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è",
                "no": "–°–≤—ñ—Ç–ª–∞ –Ω–µ–º–∞—î",
                "first": "–°–≤—ñ—Ç–ª–∞ –Ω–µ –±—É–¥–µ –ø–µ—Ä—à—ñ 30 —Ö–≤.",
                "second": "–°–≤—ñ—Ç–ª–∞ –Ω–µ –±—É–¥–µ –¥—Ä—É–≥—ñ 30 —Ö–≤"
            }
        }
    }

    # –ó–∞–ø–∏—Å—É—î–º–æ JSON
    log(f"üíæ –ó–∞–ø–∏—Å—É—é JSON ‚Üí {OUTPUT_FILE}")
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(new_json, f, ensure_ascii=False, indent=2)

    log("‚úîÔ∏è JSON —É—Å–ø—ñ—à–Ω–æ –æ–Ω–æ–≤–ª–µ–Ω–æ")
    return True


if __name__ == "__main__":
    try:
        result = asyncio.run(main())
        if result:
            log("üéâ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ")
        else:
            log("‚ÑπÔ∏è –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –±–µ–∑ –æ–Ω–æ–≤–ª–µ–Ω—å")
    except KeyboardInterrupt:
        log("‚ö†Ô∏è –ü–µ—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º")
    except Exception as e:
        log(f"‚ùå –§–∞—Ç–∞–ª—å–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
        import traceback
        log(traceback.format_exc())